{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies des grosses data](https://github.com/wikistat/Ateliers-Big-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Reconnaissance de caractères manuscrits](https://github.com/wikistat/Ateliers-Big-Data/2-MNIST) ([MNIST](http://yann.lecun.com/exdb/mnist/)) en <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 120px; display: inline\" alt=\"Python\"/></a> avec <a href=\"http://scikit-learn.org/stable/#\"><img src=\"http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\" style=\"max-width: 100px; display: inline\" alt=\"Scikit-Learn\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résumé \n",
    "Présentation du problème de reconnaissance de caractères manuscrits ([MNIST DataBase](http://yann.lecun.com/exdb/mnist/) à partir d’images numérisées. L’objectif est de comparer les performances (qualité de prévision, temps d'exécution) en fonction de latechnologie, ici Python et la librairie *Scikit-learn*, et en fonction de la taille de l'échantillon. Même interprété, les exécutions sont effecaces par une bonne parallélisation. La faiblesse concerne les insufisances des aides à l'interprétation.. \n",
    "## 1 Introduction\n",
    "### 1.1 Objetif\n",
    "L'objectif général est la construction d'un meilleur modèle de reconnaissance de chiffres manuscrits. Ce problème est ancien (zipcodes) et sert souvent de base pour la comparaison de méthodes et d'algorithmes d'apprentissage. Le site de Yann Le Cun: [MNIST](http://yann.lecun.com/exdb/mnist/) DataBase, est à la source des données étudiées, il décrit précisément le problème et les modes d'acquisition. Il tenait à jour la liste des publications proposant des solutions avec la qualité de prévision obtenue. Ce problème a également été proposé comme sujet d'un concours [Kaggle](https://www.kaggle.com/competitions) mais sur un sous-ensemble des données. \n",
    "\n",
    "De façon très schématique, plusieurs stratégies sont développées dans une vaste littérature sur ces données.  \n",
    "\n",
    "- Utiliser une méthode classique (k-nn, random forest...) sans trop raffiner mais avec des temps d'apprentissage rapide conduit à un taux d'erreur autour de 3\\%.\n",
    "* Ajouter  ou intégrer un pré-traitement des données permettant de recaler les images par des distorsions plus ou moins complexes.\n",
    "* Construire une mesure de distance adaptée au problème, par exemple invariante par rotation, translation, puis l'intégrer dans une technique d'apprentissage classique comme les $k$ plus proches voisins.\n",
    "* Utiliser une méthode plus flexibles (réseau de neurones épais) avec une optimisation fine des paramètres.\n",
    "\n",
    "L'objectif de cet atelier est de comparer sur des données relativement volumineuses les performances de différents environnements technologiques et librairies.  Une dernière question est abordée, elle concerne l'influence de la taille de l'échantillon d'apprentissage sur le temps d'exécution ainsi que sur la qualité des prévisions.\n",
    "\n",
    "\n",
    "Analyse des données avec Python noter les temps d'exécution, la précision estimée sur l'échantillon test.\n",
    "\n",
    "### 1.2 Lecture des données d'apprentissage et de test\n",
    "Les données peuvent être préalablement téléchargées ou directement lues. Ce sont celles originales du site [MNIST DataBase](http://yann.lecun.com/exdb/mnist/) mais préalablement converties au format .csv, certes plus volumineux mais plus facile à lire. Attention le fichier `mnist_train.zip` présent dans le dépôt est compressé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphiques dans la fenêtre\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données peuvent être préalablement téléchargées ou directement lues. Ce sont celles originales du site [MNIST DataBase](http://yann.lecun.com/exdb/mnist/) mais préalablement converties au format .csv, certes plus volumineux mais plus facile à lire. Attention le fichier `mnist_train.zip` présent dans le dépôt est compressé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture des données d'apprentissage\n",
    "# path=\"\" # Si les données sont dans le répertoire courant sinon:\n",
    "path=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/data/\"\n",
    "Dtrain=pd.read_csv(path+\"mnist_train.csv\",header=None)\n",
    "Dtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction puis suppression de la dernière colonne des labels\n",
    "Ltrain=Dtrain.iloc[:,784]\n",
    "Dtrain.drop(Dtrain.columns[[784]], axis=1,inplace=True)\n",
    "Dtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions de l'échantillon\n",
    "Dtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Même chose pour les données de test\n",
    "Dtest=pd.read_csv(path+\"mnist_test.csv\",header=None)\n",
    "Ltest=Dtest.iloc[:,784]\n",
    "Dtest.drop(Dtest.columns[[784]], axis=1,inplace=True)\n",
    "Dtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage d'un chiffre\n",
    "plt.figure(1, figsize=(3, 3))\n",
    "plt.imshow(np.matrix(Dtest.iloc[1,:]).reshape(28,28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données ont déjà été normalisées centrées et sont complètes. Elles ne nécessitent pas d'autre \"nettoyage\" au moins rudimentaire.\n",
    "\n",
    "Le [tutoriel](http://wikistat.fr/pdf/st-tutor3-python-scikit.pdf) d'introduction à Scikit-learn montre comment représenter les images des caractères ainsi qu'une ACP qui n'est pas reprise ici. Quelles sont néanmoins les performances de k-means sur un tel volume ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "tps1 = time.clock()\n",
    "km=KMeans(n_clusters=10,init='k-means++', \n",
    "   n_init=10, max_iter=100, tol=0.01,\n",
    "   precompute_distances=True, verbose=0, \n",
    "   random_state=None, copy_x=True, n_jobs=1)\n",
    "km.fit(Dtrain)\n",
    "tps2 = time.clock()\n",
    "print(\"Temps execution Kmeans :\", (tps2 - tps1)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Ltrain, km.labels_)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultat sans grand intérêt mais qui montre la difficulté de regouper les caractères identiques à l'aide de la distance euclidienne usuelle; il y a beaucoup de confusion entre les classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Apprentissage et prévision du test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 $K$ plus proches voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle avec un nombre k \"standard\" de voisins\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "tps1 = time.clock()\n",
    "knn = KNeighborsClassifier(n_neighbors=10,n_jobs=-1)\n",
    "digit_knn=knn.fit(Dtrain, Ltrain) \n",
    "tps2 = time.clock()\n",
    "print(\"Temps de k-nn :\",(tps2 - tps1)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprentissage et estimation de l'erreur de prévision sur l'échantillon test\n",
    "tps1 = time.clock()\n",
    "erreur=1-digit_knn.score(Dtest,Ltest)\n",
    "tps2 = time.clock()\n",
    "print(\"Temps:\",(tps2 - tps1)/60,\"Erreur:\",erreur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faudrait ré-appliquer la procédure d'otpimisation de $k$ par validation croisée décrite dans le [tutoriel](http://wikistat.fr/pdf/st-tutor3-python-scikit.pdf) d'introduction à scikit-learn. Néanmoins la solution $k=10$ est raisonnable et on retrouve une performance classique sur ce type de données: 3.3%, pour une méthode utilisée sans raffinement. \n",
    "\n",
    "C'est en effet une autre distance qu'il faudrait utiliser avec les $k$ plus proches voisins pour améliorer sensiblement les résultats mais avec un coût beaucoup plus élevé en temps de calcul. Un autre [scénario](http://wikistat.fr/pdf/st-atelier-MINST-tangent-ditance.pdf) propose ainsi le calcul d'une distance tangentielle entre les images ([Simard et al. (1998)](https://hal-ens.archives-ouvertes.fr/file/index/docid/60948/filename/Tangent_distance.pdf)). Le programme Matlab fait appel à un programme en C. L'intégration dans du code python plutôt que Matlab resterait à faire..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2  Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les forêts aléatoires sont également une approche raisonnable, à moindre coût de développement, sur ces données. Analyser en détail la liste des paramètres proposés dans l'implémentation de cet algorithme. Consulter pour ce faire la [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) en ligne.\n",
    "\n",
    "Les valeurs par défaut des paramètres sont utilisées sauf pour le nombre d'arbres: 100 au lieu de 10, et le nombre de processeurs utilisés: -1 au lieu de 1 (tous sont utilisés sauf 1 pour le système). Attention, tous les paramètres disponibles ne sont pas listés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "tps0 = time.clock()\n",
    "rf = RandomForestClassifier(n_estimators=100, \n",
    "   criterion='gini', max_depth=None, min_samples_split=2, \n",
    "   min_samples_leaf=1, max_features='auto', max_leaf_nodes=None, \n",
    "   bootstrap=True, oob_score=True, n_jobs=-1,random_state=None, verbose=0)\n",
    "rf.fit(Dtrain,Ltrain)\n",
    "tps1 = time.clock()\n",
    "print(\"Temps de configutration RF :\" ,tps1 - tps0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreur out-of-bag\n",
    "erreur_oob=1-rf.oob_score_\n",
    "tps2 = time.clock()\n",
    "print(\"Temps execution RF :\", tps2 - tps0, \"Erreur oob:\", erreur_oob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreur sur l'échantillon test\n",
    "1-rf.score(Dtest,Ltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Ltest, rf.predict(Dtest))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour les $k$ plus proches voisins, il serait utile d'optimiser certains paramètres dont le nombre d'arbres et sans doute *max_features*. L'optimisation de l'erreur *out-of-bag* plutôt qu'une procédure lourde  de validaiton croisée serait bienvenue. D'autre part, la restriction de la profondeur max des arbres pourrait réduire sensiblement les temps de calcul mais cela ne semble pas nécessaire d'autant que c'est un paramètre critique pour la qualité de la prévision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Effet de la taille l'échantillon d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le taux d'erreur de 3% obtenu sans effort d'optimisation est tout à fait correct au regard du temps passé en développement ! Plutôt que de chercher à l'optimiser, la suite du travail s'intéresse à l'effet de la taille de cet échantillon d'apprentissage sur la précision. La fonction [*learning_curve*](http://scikit-learn.org/stable/modules/generated/sklearn.learning_curve.learning_curve.html#sklearn.learning_curve) réalise ce calcul mais ne permet pas d'extraire le temps d'excution pour chaque taille. Une procédure rudimentaire est mise en oeuvre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Avec Random Forest (Scikit-learn) et 100 arbres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation  import train_test_split\n",
    "# tailles croissantes de l'échantillon d'apprentissage\n",
    "arrayErreur=np.empty((12,3))\n",
    "nArbres=100\n",
    "for i in range(1,13):\n",
    "    n=5000*i\n",
    "    arrayErreur[i-1,0]=n\n",
    "    if i==12:\n",
    "        n=59999\n",
    "    Xtrain,Xdrop,ytrain,ydrop=train_test_split(Dtrain,Ltrain,train_size=n)\n",
    "    tps1 = time.clock()\n",
    "    rf = RandomForestClassifier(n_estimators=nArbres, \n",
    "       criterion='gini', max_depth=None, min_samples_split=2, \n",
    "       min_samples_leaf=1, max_features='auto', max_leaf_nodes=None, \n",
    "       bootstrap=True, oob_score=True, n_jobs=-1,random_state=None, verbose=0)\n",
    "    rf.fit(Xtrain,ytrain)\n",
    "    tps2=time.clock()\n",
    "    arrayErreur[i-1,2]=1-rf.score(Dtest,Ltest)\n",
    "    arrayErreur[i-1,1]=tps2 - tps1\n",
    "dataframeErreur1=pd.DataFrame(arrayErreur,columns=[\"Taille\",\"Temps\",\"Erreur\"])\n",
    "print(dataframeErreur1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphes superposés\n",
    "from __future__ import division\n",
    "from scipy import *\n",
    "from pylab import *\n",
    "\n",
    "x = linspace(5,60,12)     \n",
    "fig = plt.figure()\n",
    "# premier graphe\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(x,dataframeErreur1[\"Temps\"] , '-b', label=ur\"Temps\",lw=1.5)\n",
    "# absisses communes\n",
    "xlim(0,65)\n",
    "xlabel(ur\"Taille échantillon x 1000\", color='b', fontsize=16)\n",
    "ylim(0, 70)                                                   \n",
    "ylabel(ur\"Secondes\", color='b', fontsize=16)  \n",
    "legend(loc=2)                                                  \n",
    "# 2ème graphe\n",
    "ax2 = ax1.twinx()                                              \n",
    "ax2.plot(x,dataframeErreur1[\"Erreur\"] ,'--g', label=ur\"Erreur\",lw=1.5)       \n",
    "ylim(0, 0.1)                                                  \n",
    "ylabel(ur\"Taux d'erreur\", color='g', fontsize=16)          \n",
    "legend(loc=1)                                                   \n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Avec Random Forest (Scikit-learn) et 250 arbres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation  import train_test_split\n",
    "# tailles croissantes de l'échantillon d'apprentissage\n",
    "arrayErreur=np.empty((12,3))\n",
    "nArbres=250\n",
    "for i in range(1,13):\n",
    "    n=5000*i\n",
    "    arrayErreur[i-1,0]=n\n",
    "    if i==12:\n",
    "        n=59999\n",
    "    Xtrain,Xdrop,ytrain,ydrop=train_test_split(Dtrain,Ltrain,train_size=n)\n",
    "    tps1 = time.clock()\n",
    "    rf = RandomForestClassifier(n_estimators=nArbres, \n",
    "       criterion='gini', max_depth=None, min_samples_split=2, \n",
    "       min_samples_leaf=1, max_features='auto', max_leaf_nodes=None, \n",
    "       bootstrap=True, oob_score=True, n_jobs=-1,random_state=None, verbose=0)\n",
    "    rf.fit(Xtrain,ytrain)\n",
    "    tps2=time.clock()\n",
    "    arrayErreur[i-1,2]=1-rf.score(Dtest,Ltest)\n",
    "    arrayErreur[i-1,1]=tps2 - tps1\n",
    "dataframeErreur=pd.DataFrame(arrayErreur,columns=[\"Taille\",\"Temps\",\"Erreur\"])\n",
    "print(dataframeErreur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphes supersosés\n",
    "from __future__ import division\n",
    "from scipy import *\n",
    "from pylab import *\n",
    "\n",
    "x = linspace(5,60,12)     \n",
    "fig = plt.figure()\n",
    "# premier graphe\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(x,dataframeErreur[\"Temps\"] , '-b', label=ur\"Temps\",lw=1.5,marker=\".\",markersize=6)\n",
    "# absisses communes\n",
    "xlim(0,65)\n",
    "xlabel(ur\"Taille échantillon x1000\", fontsize=15)\n",
    "ylim(0, 100)                                                   \n",
    "ylabel(ur\"Temps (s)\", color='b', fontsize=15)  \n",
    "legend(loc=2)                                                  \n",
    "# 2ème graphe\n",
    "ax2 = ax1.twinx()                                              \n",
    "ax2.plot(x,dataframeErreur[\"Erreur\"] ,'--',color='black', label=ur\"Erreur\",lw=1.5,marker=\".\",markersize=6)       \n",
    "ylim(0, 0.1)                                                  \n",
    "ylabel(ur\"Erreur (%)\",  fontsize=15)          \n",
    "legend(loc=1)                                                   \n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparer les résultats obtenus (temps, précision) avec R."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "244px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
