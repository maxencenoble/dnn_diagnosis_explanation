{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 250px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction aux SVM en R\n",
    "\n",
    "** Objectifs : ** \n",
    "\n",
    "- Apprendre à manipuler les SVM pour la classification en R avec la librairie **`kernlab`**\n",
    "- Observer l'effet du noyau et de la pénalité sur les règles de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM linéaires :\n",
    "\n",
    "## Génération des données\n",
    "\n",
    "On commence par générer un jeu de données \"jouet\" : deux échantillons gaussiens en dimension 2 pour la visualisation avce des moyennes de signes différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation  des variables explicatives :\n",
    "\n",
    "n=80\n",
    "p=2\n",
    "s=1\n",
    "m1=0\n",
    "m2=3\n",
    "\n",
    "x1=matrix(rnorm(n*p,mean=m1,sd=s),n,p)\n",
    "x2=matrix(rnorm(n*p,mean=m2,sd=s),n,p)\n",
    "x=rbind(x1,x2)\n",
    "dim(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Génération des labels\n",
    "y=matrix(c(rep(-1,n),rep(1,n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des données\n",
    "plot(x,col=ifelse(y>0,1,2))\n",
    "legend(\"topleft\", c('y=1','y=-1'),col=c(1,2),pch=1, text.col=c(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Echantillon d'apprentissage et échantillon test\n",
    "#ntrain=round(1.5*n)\n",
    "index=sample(2*n,round(1.5*n))\n",
    "xtrain = x[index,]\n",
    "xtest= x[-index,]\n",
    "ytrain=y[index]\n",
    "ytest=y[-index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage d'un SVM linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(kernlab)\n",
    "help(ksvm)\n",
    "linsvm=ksvm(xtrain, ytrain,type=\"C-svc\",kernel='vanilladot',C=100)\n",
    "summary(linsvm)\n",
    "linsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes(linsvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphaindex(linsvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha(linsvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b(linsvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(linsvm,data=xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=predict(linsvm,xtest)\n",
    "ypred\n",
    "table(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taux de bonnes prédictions\n",
    "sum(ypred==ytest)/length(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredscore=predict(linsvm,xtest,type=\"decision\")\n",
    "ypredscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Tracé des courbes ROC **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ROCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred=prediction(ypredscore,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe ROC :\n",
    "res1=performance(pred,measure=\"tpr\",x.measure=\"fpr\")\n",
    "plot(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance en fonction du seuil\n",
    "res3=performance(pred,measure=\"acc\")\n",
    "plot(res3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Estimation de l'erreur par validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linsvm=ksvm(x, y,type=\"C-svc\",kernel='vanilladot',C=1,cross=5)\n",
    "summary(linsvm)\n",
    "linsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross(linsvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(linsvm,data=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation du paramètre $C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linsvm=ksvm(x, y,type=\"C-svc\",kernel='vanilladot',C=10,cross=5)\n",
    "summary(linsvm)\n",
    "linsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(linsvm,data=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Que constatez-vous sur l'erreur estimée par validation croisée ? Comment expliquez vous ce phénomène ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Ecrire un programme qui permet de tracer en fonction de $C$ l'erreur estimée par validation croisée. Refaire ce tracé avec des données moins nettement séparées (par exemple en prenant $m1=1$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM non linéaires\n",
    "\n",
    "## Génération des données : \n",
    "\n",
    "On génère des données qui ne seront pas linéairement séparables : pour cela, chacun des deux jeux de données est généré selon un mélange gaussien : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation  des variables explicatives\n",
    "n=40\n",
    "p=2\n",
    "s=1\n",
    "m1=0\n",
    "m2=3\n",
    "\n",
    "x11=matrix(rnorm(n*p,mean=m1,sd=s),n,p)\n",
    "\n",
    "x12=matrix(c(rnorm(n,mean=m1,sd=s),rnorm(n,mean=m2,sd=s)),n,p)\n",
    "\n",
    "x21=matrix(c(rnorm(n,mean=m2,sd=s),rnorm(n,mean=m1,sd=s)),n,p)\n",
    "\n",
    "x22=matrix(rnorm(n*p,mean=m2,sd=s),n,p)\n",
    "\n",
    "x=rbind(x11,x22,x12,x21)\n",
    "dim(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Génération des labels\n",
    "y=matrix(c(rep(-1,2*n),rep(1,2*n)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des données\n",
    "plot(x,col=ifelse(y>0,1,2))\n",
    "legend(\"topleft\", c('y=1','y=-1'),col=c(1,2),pch=1, text.col=c(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au lieu d'utiliser un noyau linéaire, nous allons utiliser un noyau gaussien. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussvm=ksvm(x,y,type=\"C-svc\",kernel='rbf',kpar=list(sigma=1),C=10^10,cross=5)\n",
    "plot(gaussvm, data=x)\n",
    "print(gaussvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection automatique de sigma\n",
    "gaussvm=ksvm(x,y,type=\"C-svc\",kernel='rbf',C=1,cross=5)\n",
    "plot(gaussvm, data=x)\n",
    "print(gaussvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q. ** Tracer en fonction de $C$ :\n",
    "- l'erreur d'apprentissage, l'erreur estimée par validation croisée \n",
    "- le nombre de support vectors retenus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q.** Tester la méthode avec d'autres noyaux et voyez l'importance du choix du noyau ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Application à des données génomiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data frame with 106 observations and 58 variables. The first variableClass\n",
    "is a factor with levels ** + ** for a promoter gene and ** - **\n",
    "for a non-promoter gene.  The remaining 57 variables V2 to V58 are factors describing the sequence. \n",
    "The DNA bases are coded as follows:\n",
    "- a : adenine\n",
    "- c : cytosine\n",
    "- g : guanine\n",
    "- t: thymine\n",
    "\n",
    "Réf. : Powell, G., Shavlik, J. and Noordewier, M.\n",
    "Refinement of Approximate Domain Theories by Knowledge-Based Artificial Neural Networks.\n",
    "In Proceedings of the Eighth National Conference on Artificial Intelligence (AAAI-90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data(promotergene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(promotergene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ksvm(Class~.,data=promotergene,kernel=\"laplacedot\", kpar=\"automatic\",C=5,cross=4)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=promotergene[,-1]\n",
    "y=promotergene$Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cpred=predict(model,x)\n",
    "\n",
    "table(Cpred,y)\n",
    "# Attention, on ne voit ici que l'erreur apparente ! Regarder l'erreur estimée par cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification multi-classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la classification multiclasses ($k>2$), la fonction **`ksvm`** utilise une approche \"one-againts one\"\", dans laquelle $k(k-1)/2$ classifieurs binaires sont entrainés. La classe est attribuée par un vote majoritaire. \n",
    "\n",
    "D'autres algorithmes utilisent une approche \"one versus all\", où on teste à chaque fois une classe contre toutes les autres. On a alors $k$ classifieurs à construire et on retient généralement la classe qui permet d'avoir la plus grande marge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation  des variables explicatives\n",
    "n=40\n",
    "p=2\n",
    "s=1\n",
    "m1=0\n",
    "m2=3\n",
    "\n",
    "x11=matrix(rnorm(n*p,mean=m1,sd=s),n,p)\n",
    "\n",
    "x12=matrix(c(rnorm(n,mean=m1,sd=s),rnorm(n,mean=m2,sd=s)),n,p)\n",
    "\n",
    "x21=matrix(c(rnorm(n,mean=m2,sd=s),rnorm(n,mean=m1,sd=s)),n,p)\n",
    "\n",
    "x22=matrix(rnorm(n*p,mean=m2,sd=s),n,p)\n",
    "\n",
    "x=rbind(x11,x22,x12,x21)\n",
    "dim(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Génération des labels\n",
    "n=40\n",
    "y=matrix(c(rep(1,n),rep(2,n),rep(3,n),rep(4,n)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des données\n",
    "plot(x,col=y)\n",
    "legend(\"topleft\", c('y=1','y=2',\"y=3\",\"y=4\"),col=c(1,2,3,4),pch=1, text.col=c(1,2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model <- ksvm(x,y,type=\"C-svc\",kernel=\"rbfdot\",C=10,prob.model=TRUE,cross=5)\n",
    "model\n",
    "## get fitted values\n",
    "fitted(model)\n",
    "## Test on the training set with probabilities as output\n",
    "#ypred=predict(irismodel, x, type=\"probabilities\")\n",
    "ypred=predict(model, x)\n",
    "table(y,ypred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data(iris)\n",
    "## Create a kernel function using the build in rbfdot function\n",
    "rbf <- rbfdot(sigma=0.1)\n",
    "rbf\n",
    "## train a bound constraint support vector machine\n",
    "irismodel <- ksvm(Species~.,data=iris,type=\"C-bsvc\",kernel=rbf,C=10,prob.model=TRUE,cross=5)\n",
    "irismodel\n",
    "## get fitted values\n",
    "irispred=fitted(irismodel)\n",
    "\n",
    "table(irispred,iris$Species)\n",
    "## Test on the training set with probabilities as output\n",
    "#predict(irismodel, iris[,-5], type=\"probabilities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
