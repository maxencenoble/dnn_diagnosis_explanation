{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  [High Dimensional and Deep Learning](https://github.com/wikistat/High-Dimensional-Deep-Learning ):  [Reconnaissance d'Activité Humaine](https://github.com/wikistat/High-Dimensional-Deep-Learning/blob/master/FunctionalDecomposition/Python%20-%20HAR.ipynb) ([*HAR*](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)) en <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 120px; display: inline\" alt=\"Python\"/></a>   Anomaly Detection\n",
    "\n",
    "## 1.1 Context\n",
    "\n",
    "\n",
    "The objective is to recognize the activity of an individual from a set of signals recorded on a smartphone from the embedded gyroscope and accelerometer. A learning database has been built experimentally. A set of persons  performed a determined activity for a predefined period of time while signals were recorded. The data come from the community that aims to recognize human activities (Human activity recognition, HAR). See the [paper](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-11.pdf) on a symposium in 2013. The analysis of data associated with real-time activity identification is not discussed.\n",
    "\n",
    "The available public data was acquired, described and partly analyzed by [Anguita et al. (2013)](https://www.icephd.org/sites/default/files/IWAAL2012.pdf). They are available on the University California Irvine (UCI) [repository](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) dedicated to machine learning.\n",
    "\n",
    "The archive contains the raw data: accelerations sampled at 64 htz during 2s. The accelerations in x, y, and z (body_acc), each contains 128 columns, those by subtracting the natural gravity (total_acc) as well as the angular accelerations in x, y, and z obtained from the gyroscope (body_gyro). The choice of a power of 2 for the sampling frequency allows the efficient execution of Fourier transform or wavelet transform algorithms.\n",
    "\n",
    "\n",
    "The *features data* have been built by experts of signal processing from the *a priori* knowledge on the behaviour of the different activities we want to study. We will see that it is quite easy to achieve good performances for the anomaly detection problem using these features data.\n",
    "\n",
    "\n",
    "The objective of this TP is to detect anomalies from the *features* data and from simple transformations of the raw data. \n",
    "\n",
    "## 1.2 Objectives : \n",
    "\n",
    "- Apply several anomaly detection methods on the *features* data :  \n",
    "  - Hierarchical clustering (CAH : Classification ascendante hiérarchique)\n",
    "  - One-class SVM\n",
    "  - Local Outlier Factor\n",
    "  - Isolation Forest\n",
    "  \n",
    " \n",
    "- Anomaly detection on the functional data : transformation of the raw data onto new features (PCA, wavelet decomposition, Fast Fourier Transform) on which we apply the previous mentioned anomaly detection methods.\n",
    "\n",
    "\n",
    "- As in the previous TP for classification purposes, the objective is here to obtain as good performances for anomaly detection as on  the *features* data with simple transformations of the raw signals. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ACP\n",
    "import sklearn.decomposition as sd\n",
    "import sklearn.preprocessing as sp\n",
    "\n",
    "# Hierarchical clustering\n",
    "import scipy.cluster.hierarchy as sch\n",
    "# LOF\n",
    "import sklearn.neighbors as sn\n",
    "# Isolation Forest\n",
    "import sklearn.ensemble as se\n",
    "\n",
    "# Plot et Display\n",
    "import utils.illustration as uil\n",
    "import utils.load as ul\n",
    "\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set()\n",
    "sb.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIGNALS = [ \"body_acc_x\", \"body_acc_y\", \"body_acc_z\", \"body_gyro_x\", \"body_gyro_y\", \"body_gyro_z\"]\n",
    "CMAP = plt.get_cmap(\"Set1\")\n",
    "ACTIVITY_DIC = {1 : \"WALKING\",\n",
    "2 : \"WALKING UPSTAIRS\",\n",
    "3 : \"WALKING DOWNSTAIRS\",\n",
    "4 : \"SITTING\",\n",
    "5 : \"STANDING\",\n",
    "6 : \"LAYING\"}\n",
    "COLOR_DIC = {v:CMAP(k-2) if v!=\"WALKING\" else CMAP(10) for k,v in ACTIVITY_DIC.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2  The data\n",
    "### 2.2.1 Loading the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../data/HumanActivityRecognition\"\n",
    "#Multidimensional Data\n",
    "X_train = ul.load_signals(data_path,\"train\", SIGNALS)\n",
    "Y_train_label = ul.load_y(data_path, \"train\")\n",
    "X_train_metier= ul.my_read_csv(data_path+\"/train/X_train.txt\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Constitution of the datasets with anomalies\n",
    "\n",
    "We build a dataset with\n",
    "\n",
    "   * `N_normal` signals considered as *normal*  (corresponding to the class *WALKING*).  \n",
    "   * `N_anormal` signals of each type of *abnormal* signals  (*WALKING UPSTAIRS*, *WALKING DOWNSTAIRS*, *SITTING*, *STANDING*, *LAYING*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_normal = 800\n",
    "N_anormal = 2\n",
    "\n",
    "# New Y Label\n",
    "Y= np.hstack([np.repeat(1,N_normal)] + [np.repeat(i, N_anormal) for i in range(2,7)])\n",
    "Y_label = np.array([ACTIVITY_DIC[y] for y in Y])\n",
    "#New X Data\n",
    "index_per_act = np.hstack([np.where(Y_train_label==1)[0][:N_normal]] + [np.where(Y_train_label==act)[0][:N_anormal] for act in range(2,7)])\n",
    "\n",
    "X = X_train[index_per_act]\n",
    "X_metier = X_train_metier[index_per_act]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each type of signal, a sample of the normal behavior and the different anomalies are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_sample_per_activity = dict([(v,50) if v==\"WALKING\" else (v,N_anormal) for k,v in ACTIVITY_DIC.items()])\n",
    "linestyle_per_activity = dict([(v,\"dashed\") if v==\"WALKING\" else (v,\"solid\") for k,v in ACTIVITY_DIC.items()])\n",
    "linewidth_per_activity = dict([(v,1) if v==\"WALKING\" else (v,2) for k,v in ACTIVITY_DIC.items()])\n",
    "\n",
    "fig = plt.figure(figsize=(16,18))    \n",
    "uil.plot_signaux(fig, X, Y_label, SIGNALS, COLOR_DIC, nb_sample_per_activity, \n",
    "             linestyle_per_activity, linewidth_per_activity, figdim1 = 3, figdim2 = 2, legend=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Principal components analysis\n",
    "### 2.3.1  For the signal : acceleration in  x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isignal = 0\n",
    "print(\"ACP on signal \" + SIGNALS[isignal])\n",
    "X_signal = np.vstack([x[:,isignal] for x in X])\n",
    "\n",
    "acp = sd.PCA()\n",
    "X_acp_signal = acp.fit_transform(sp.scale(X_signal))\n",
    "\n",
    "X_signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = X.shape[0]\n",
    "colors=[COLOR_DIC[y] for y in Y_label]\n",
    "markersizes = [60 if y==1 else 140 for y in Y]\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_signal, acp, colors=colors, markersizes = markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Comment these results from the perspective of anomaly detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2  For all the signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_signaux = np.vstack([x.reshape(128*6) for x in X])\n",
    "acp = sd.PCA()\n",
    "X_acp_signaux = acp.fit_transform(sp.scale(X_signaux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_signaux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_signaux, acp, colors, markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 For the *features* data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acp = sd.PCA()\n",
    "X_acp_metier = acp.fit_transform(sp.scale(X_metier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_metier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_metier, acp, colors, markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q.** Comment these results from the perspective of anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Anomaly detection of the *features* data \n",
    "\n",
    "It seems quite easy to detect the anomalies from the *features* data. We apply the classical methods studied during the course: hierarchical clustering with the \"single\" option,  One class SVM, Local Outlier Factor and Isolation Forest. \n",
    "The different methods have not been optimized. Study the impact of the different parameters on the anomaly detection performances. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Hierarchical clustering (Classification Ascendante Hiérarchique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = sch.linkage(X_metier, 'single')\n",
    "C = np.array([c[0] for c in sch.cut_tree(Z,6)])\n",
    "\n",
    "CT_HCA = pd.DataFrame(list(zip(C,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_HCA.pred, CT_HCA.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = [\"\" if y==\"WALKING\" else y for y in Y_label]\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "sch.dendrogram( Z, p=6, leaf_rotation=45.,leaf_font_size=15,labels=LABELS, truncate_mode=\"level\"  # font size for the x axis labels\n",
    ")\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "\n",
    "ax =fig.get_axes()[0]\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    if lbl.get_text() in COLOR_DIC:\n",
    "        lbl.set_color(COLOR_DIC[lbl.get_text()])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2  One class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.05)\n",
    "\n",
    "OCS.fit(X_metier)\n",
    "pred = OCS.predict(X_metier)\n",
    "\n",
    "CT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_svm.pred, CT_svm.Anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_svm,COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contamination=0.05\n",
    "metric = \"euclidean\"\n",
    "n_neighbors = 15\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric)\n",
    "y_pred = clf.fit_predict(X_metier)\n",
    "\n",
    "CT_metier_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_metier_lof.pred, CT_metier_lof.Anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_metier_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = se.IsolationForest(n_estimators=100, contamination=0.05, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_metier)\n",
    "y_pred = clf.predict(X_metier)\n",
    "\n",
    "CT_IF = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_IF.pred, CT_IF.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_IF, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q. ** What is your  conclusion on the *features* data ? \n",
    "\n",
    "The objective of the next sections is to try to detect the  anomalies from the raw data or from simple transformations of the raw data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Anomaly detection on the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Hierarchical clustering\n",
    "\n",
    "We first use a single signal : acceleration in x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = sch.linkage(X_signal,'single')\n",
    "\n",
    "C = np.array([c[0] for c in sch.cut_tree(Z,6)])\n",
    "\n",
    "CT_HCA = pd.DataFrame(list(zip(C,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_HCA.pred, CT_HCA.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = [\"\" if y==\"WALKING\" else y for y in Y_label]\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "sch.dendrogram( Z, p=6, leaf_rotation=45.,leaf_font_size=15,labels=LABELS, truncate_mode=\"level\"  # font size for the x axis labels\n",
    ")\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "\n",
    "ax =fig.get_axes()[0]\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    if lbl.get_text() in COLOR_DIC:\n",
    "        lbl.set_color(COLOR_DIC[lbl.get_text()])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** How many anomalies have been detected? Do you get better results by taking all the signals?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 One class SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 On the two first PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.01)\n",
    "\n",
    "OCS.fit(X_acp_signal[:,:2])\n",
    "pred = OCS.predict(X_acp_signal[:,:2])\n",
    "\n",
    "CT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_svm.pred, CT_svm.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Comment on the results. Do you get better results by increasing the number of components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_acp = X_acp_signal\n",
    "nu = 0.02\n",
    "\n",
    "# fit the model\n",
    "clf = ssvm.OneClassSVM(kernel=\"rbf\",nu=nu)\n",
    "clf.fit(X_acp[:,:2])\n",
    "y_pred_train = clf.predict(X_acp[:,:2])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "markersizes = [10 if y==1 else 20 for y in Y]\n",
    "labels = [\"\"] * N \n",
    "for il, l in [(np.where(Y_label==y)[0][0],y) for y in set(Y_label)]:\n",
    "    labels[il] = l\n",
    "\n",
    "uil.plot_decision_function(fig, ax, clf, X_acp, y_pred_train, colors=colors, labels = labels, markersizes=markersizes)\n",
    "ax.set_title(\"Novelty Detection : nu=%.1f\" %nu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_svm, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 On the acceleration in x :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.05)\n",
    "\n",
    "OCS.fit(X_signal)\n",
    "pred = OCS.predict(X_signal)\n",
    "\n",
    "CT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_svm.pred, CT_svm.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Comment on the results. Does applying the method on all the signals improve the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Local Outlier Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 On the acceleration in  x : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contamination=0.05\n",
    "metric = \"euclidean\"\n",
    "n_neighbors = 15\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric)\n",
    "y_pred = clf.fit_predict(X_signal)\n",
    "\n",
    "CT_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_lof.pred, CT_lof.Anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contamination=0.05\n",
    "metric = \"euclidean\"\n",
    "n_neighbors = 15\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric)\n",
    "y_pred = clf.fit_predict(X_signaux)\n",
    "\n",
    "CT_tous_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_tous_lof.pred, CT_tous_lof.Anomaly))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Comment on the results. Do you get better performances on all the signals? By changing the parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 On the PCA components : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_acp = X_acp_signal\n",
    "n_neighbors = 15\n",
    "\n",
    "# fit the model\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric = metric)\n",
    "y_pred = clf.fit_predict(X_acp[:,:2])\n",
    "\n",
    "CT_ACP_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_lof.pred, CT_ACP_lof.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_ACP_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "\n",
    "## Souci : les anomalies détectées ne s'affichent pas !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 On the acceleration in  x :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = se.IsolationForest(n_estimators=100, contamination=0.05, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "\n",
    "clf.fit(X_signal)\n",
    "y_pred = clf.predict(X_signal)\n",
    "\n",
    "CT_IF = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_IF.pred, CT_IF.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_IF, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 On the PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_acp = X_acp_signal\n",
    "\n",
    "contamination=0.05\n",
    "clf = se.IsolationForest(n_estimators=100, contamination=contamination, bootstrap=True, n_jobs=-1)\n",
    "clf.fit(X_acp[:,:2])\n",
    "y_pred = clf.predict(X_acp[:,:2])\n",
    "\n",
    "CT_IF = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_IF.pred, CT_IF.Anomaly))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Do you get better results by increasing the number of PCA components ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In conclusion**, the anomaly detection methods applied directly to the signals do not work well. We will see in the next section if the projection onto a wavelet basis allows to obtain better results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Anomaly detection based  wavelet decompositions of the signals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Wavelet decomposition\n",
    "\n",
    "We work with the acceleration in x.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "from pywt import wavedec\n",
    "\n",
    "from statsmodels.robust import mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isignal = 0\n",
    "print(\" signal \" + SIGNALS[isignal])\n",
    "X_signal = np.vstack([x[:,isignal] for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "wf = \"haar\"\n",
    "\n",
    "Coeff = []\n",
    "TCoeff = []\n",
    "for x in X_signal :\n",
    "    #Apply wavelet decomposition\n",
    "    coeffs = pywt.wavedec(x,wf,level=7)\n",
    "    coeffs_flatten = np.hstack(coeffs)\n",
    "    Coeff.append(coeffs_flatten)\n",
    "    \n",
    "    # Compute universal Threshold http://jseabold.net/blog/2012/02/23/wavelet-regression-in-python/\n",
    "    sigma = mad(coeffs[-1])\n",
    "    uthresh = sigma*np.sqrt(2*np.log(128))\n",
    "    # Apply Threshold on 4 last levels\n",
    "    coeffs_thresh = [pywt.threshold(c, uthresh, mode=\"hard\") if i<=3 else c for i,c in enumerate(coeffs[::-1])]\n",
    "    coeffs_thresh_flatten = np.hstack(coeffs_thresh[::-1])\n",
    "    TCoeff.append(coeffs_thresh_flatten)\n",
    "    \n",
    "Coeff = np.array(Coeff)\n",
    "TCoeff = np.array(TCoeff)\n",
    "print(Coeff.shape, TCoeff.shape)\n",
    "print(np.sum(Coeff!=0), np.sum(TCoeff!=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only keep the coefficients from levels 1 to 4, the others are considered as noise and are canceled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Coefficients dfrom levels  1 to 4 : \n",
    "CoeffA4=Coeff[:,:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 PCA of the wavelet coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acp = sd.PCA()\n",
    "X_acp_ond = acp.fit_transform(sp.scale(Coeff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_ond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markersizes = [60 if y==1 else 140 for y in Y]\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_ond, acp, colors, markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 PCA of the wavelet coefficients from levels 1 to 4 :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acp = sd.PCA()\n",
    "X_acp_ondA4 = acp.fit_transform(sp.scale(CoeffA4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_ondA4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markersizes = [60 if y==1 else 140 for y in Y]\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_ondA4, acp, colors, markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comment these results in the perspective of anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = sch.linkage(Coeff, 'single')\n",
    "C = np.array([c[0] for c in sch.cut_tree(Z,6)])\n",
    "\n",
    "CT_HCA = pd.DataFrame(list(zip(C,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_HCA.pred, CT_HCA.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = [\"\" if y==\"WALKING\" else y for y in Y_label]\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "sch.dendrogram( Z, p=6, leaf_rotation=45.,leaf_font_size=15,labels=LABELS, truncate_mode=\"level\"  # font size for the x axis labels\n",
    ")\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "\n",
    "ax =fig.get_axes()[0]\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    if lbl.get_text() in COLOR_DIC:\n",
    "        lbl.set_color(COLOR_DIC[lbl.get_text()])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 One class SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.1 On all the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.05)\n",
    "\n",
    "OCS.fit(Coeff)\n",
    "pred = OCS.predict(Coeff)\n",
    "\n",
    "CT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_svm.pred, CT_svm.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Do we get better results with thresholded coefficients? With the coefficients of level 1 to 4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Local Outlier Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.1 On the coefficients from  levels  1 to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contamination=0.05\n",
    "metric = \"euclidean\"\n",
    "n_neighbors = 15\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric)\n",
    "y_pred = clf.fit_predict(CoeffA4)\n",
    "\n",
    "CT_ond_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_ond_lof.pred, CT_ond_lof.Anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_ond_lof, COLOR_DIC, normal_behaviour=\"WALKING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Do you get better results with all the coefficients? With the thresholded coefficients? With higher level coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.1 On all the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = se.IsolationForest(n_estimators=100, contamination=0.05, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "clf.fit(Coeff)\n",
    "y_pred = clf.predict(Coeff)\n",
    "\n",
    "CT_IF = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_IF.pred, CT_IF.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Do we get better results with thresholded coefficients? With the coefficients of levels 1 to 4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.**We only worked on the acceleration in x. Does considering all the signals improve the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion :** The anomaly detection methods that we have considered, applied on wavelet transformations of the raw signals, do not detect anomalies. In the next section, we will see if the Fourier transform allows to improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Anomaly detection with the FFT coefficients\n",
    "## 6.1 Computation of the FFT coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FFT Coefficients : \n",
    "\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "isignal = 0\n",
    "print(\" signal \" + SIGNALS[isignal])\n",
    "X_signal = np.vstack([x[:,isignal] for x in X])\n",
    "\n",
    "#print(amplitudefft)\n",
    "#plt.plot(amplitudefft)\n",
    "\n",
    "fftCoeff = []\n",
    "\n",
    "for x in X_signal :\n",
    "    \n",
    "    mx=np.mean(x)\n",
    "    x_centre=x-mx\n",
    "   #Apply fast Fourier transform\n",
    "    coeffsfft=np.abs(fft(x_centre))  \n",
    "    coeffsfft_flatten = np.hstack(coeffsfft)\n",
    "    fftCoeff.append(coeffsfft_flatten)\n",
    "        \n",
    "fftCoeff = np.array(fftCoeff)\n",
    "\n",
    "# Just keep half of the coefficients (they are then repeated symmetrically)\n",
    "\n",
    "fftCoeff=fftCoeff[:,:64]\n",
    "print(fftCoeff.shape)\n",
    "print(np.sum(fftCoeff!=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 PCA of the FFT coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acp = sd.PCA()\n",
    "X_acp_fft = acp.fit_transform(sp.scale(fftCoeff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_fft, acp, colors, markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Which signals differ from the others? Is this consistent with what has been seen in the previous notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = sch.linkage(fftCoeff, 'single')\n",
    "C = np.array([c[0] for c in sch.cut_tree(Z,6)])\n",
    "\n",
    "CT_HCA = pd.DataFrame(list(zip(C,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_HCA.pred, CT_HCA.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = [\"\" if y==\"WALKING\" else y for y in Y_label]\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "sch.dendrogram( Z, p=6, leaf_rotation=45.,leaf_font_size=15,labels=LABELS, truncate_mode=\"level\"  # font size for the x axis labels\n",
    ")\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "\n",
    "ax =fig.get_axes()[0]\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    if lbl.get_text() in COLOR_DIC:\n",
    "        lbl.set_color(COLOR_DIC[lbl.get_text()])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comment the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 One class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.05)\n",
    "\n",
    "OCS.fit(fftCoeff)\n",
    "pred = OCS.predict(fftCoeff)\n",
    "\n",
    "CT_FFT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_FFT_svm.pred, CT_FFT_svm.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Study the impact of the kernel and of the parameter nu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contamination=0.05\n",
    "metric = \"euclidean\"\n",
    "n_neighbors = 15\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric)\n",
    "y_pred = clf.fit_predict(fftCoeff)\n",
    "\n",
    "CT_FFT_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_FFT_lof.pred, CT_FFT_lof.Anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_FFT_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q.** Comment on the results and see the impact of the parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = se.IsolationForest(n_estimators=100, contamination=0.05, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "clf.fit(fftCoeff)\n",
    "y_pred = clf.predict(fftCoeff)\n",
    "\n",
    "CT_IF = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_IF.pred, CT_IF.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 6.7 Visualisation of the  LOF results\n",
    "\n",
    "The LOF method is one of the most powerful whatever the type of \"features\" considered. The results of this method are visualized for the various cases considered in the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40,40))\n",
    "ax = fig.add_subplot(3,2,1)\n",
    "uil.plot_detection_result(fig, ax, CT_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"Raw data- Boddy acc x \", fontsize=25)\n",
    "ax = fig.add_subplot(3,2,2)\n",
    "uil.plot_detection_result(fig, ax, CT_tous_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"Raw data- All the signals\", fontsize=25)\n",
    "ax = fig.add_subplot(3,2,3)\n",
    "uil.plot_detection_result(fig, ax, CT_ACP_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"PCA, 2 first components\", fontsize=25)\n",
    "ax = fig.add_subplot(3,2,4)\n",
    "uil.plot_detection_result(fig, ax, CT_ond_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"Wavelet coefficients, levels 1 to 4 \", fontsize=25)\n",
    "ax = fig.add_subplot(3,2,5)\n",
    "uil.plot_detection_result(fig, ax, CT_metier_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"Features Data\", fontsize=25)\n",
    "ax = fig.add_subplot(3,2,6)\n",
    "uil.plot_detection_result(fig, ax, CT_FFT_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"FFT coefficients\", fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Conclusion\n",
    "\n",
    "We have studied various methods for anomaly detection. On the *features* data, it is quite easy  to detect the anomalies. On the functional raw data, we have seen the importance of defining good \"features\" to highlight the anomalies: the methods of detection of anomalies applied to the raw signals or their wavelet transform, have certainly not been totally optimized but do not give good results in this case. On the other hand, the Fast Fourier Transform highlights the anomalies for these data. We can not draw a generality : on simulated telemetry data of the available notebook [here](https://github.com/wikistat/High-Dimensional-Deep-Learning/blob/master/AnomalyDetection/Python-Anomaly-Detection.ipynb), the transformation onto a wavelet basis is relevant for the detection of anomalies for these functional data. It is therefore important to know the data and the type of anomalies that you want to detect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "592px",
    "left": "0px",
    "right": "957px",
    "top": "107px",
    "width": "259px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
